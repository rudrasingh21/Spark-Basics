{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SHORT DATA for each order ID in desc order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordersItem = sc.textFile(\"/home/ubuntu/Data-For-Spark/data-master/retail_db/order_items/part-00000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,1,957,1,299.98,299.98'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordersItem.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordersItem_Map = ordersItem.map(lambda i: (int(i.split(\",\")[1]), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '1,1,957,1,299.98,299.98'),\n",
       " (2, '2,2,1073,1,199.99,199.99'),\n",
       " (2, '3,2,502,5,250.0,50.0'),\n",
       " (2, '4,2,403,1,129.99,129.99'),\n",
       " (4, '5,4,897,2,49.98,24.99')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordersItem_Map.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordersItem_Map_GroupByOrderId = ordersItem_Map.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de438>)\n",
      "(2, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de400>)\n",
      "(4, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de358>)\n",
      "(5, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5dec88>)\n",
      "(7, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de2b0>)\n",
      "(8, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de278>)\n",
      "(9, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de208>)\n",
      "(10, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de1d0>)\n",
      "(11, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de198>)\n",
      "(12, <pyspark.resultiterable.ResultIterable object at 0x7fa50c5de160>)\n"
     ]
    }
   ],
   "source": [
    "for i in ordersItem_Map_GroupByOrderId.take(10): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "oredrItemSorted_MAP= ordersItem_Map_GroupByOrderId.map(lambda i: sorted(i[1],key = lambda k: float(k.split(\",\")[4]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(oredrItemSorted_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:- Because we are using MAP so it will return a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1,1,957,1,299.98,299.98']\n",
      "['3,2,502,5,250.0,50.0', '2,2,1073,1,199.99,199.99', '4,2,403,1,129.99,129.99']\n",
      "['6,4,365,5,299.95,59.99', '8,4,1014,4,199.92,49.98', '7,4,502,3,150.0,50.0', '5,4,897,2,49.98,24.99']\n",
      "['9,5,957,1,299.98,299.98', '12,5,957,1,299.98,299.98', '10,5,365,5,299.95,59.99', '13,5,403,1,129.99,129.99', '11,5,1014,2,99.96,49.98']\n",
      "['15,7,957,1,299.98,299.98', '14,7,1073,1,199.99,199.99', '16,7,926,5,79.95,15.99']\n"
     ]
    }
   ],
   "source": [
    "for i in oredrItemSorted_MAP.take(5):print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:- If we want data as array, then use FLATMAP(). If we want a single result set then use MAP()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oredrItemSorted_FlatMap = ordersItem_Map_GroupByOrderId.flatMap(lambda i: sorted(i[1],key = lambda k: float(k.split(\",\")[4]), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,957,1,299.98,299.98\n",
      "3,2,502,5,250.0,50.0\n",
      "2,2,1073,1,199.99,199.99\n",
      "4,2,403,1,129.99,129.99\n",
      "6,4,365,5,299.95,59.99\n"
     ]
    }
   ],
   "source": [
    "for i in oredrItemSorted_FlatMap.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(oredrItemSorted_FlatMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
